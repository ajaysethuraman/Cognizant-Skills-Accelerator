{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MbkdJaykTED"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from nltk.corpus import gutenberg\n",
        "import nltk\n",
        "\n",
        "# Load the trained model\n",
        "model = tf.keras.models.load_model('text_generation_lstm.h5')\n",
        "\n",
        "# Load the same dataset used for training\n",
        "nltk.download('gutenberg')\n",
        "text = gutenberg.raw('shakespeare-hamlet.txt').lower()\n",
        "\n",
        "# Create character mappings\n",
        "chars = sorted(list(set(text)))\n",
        "char_to_int = {char: number for number, char in enumerate(chars)}\n",
        "int_to_char = {number: char for number, char in enumerate(chars)}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(seed_text, length=500, temperature=1.0):\n",
        "    generated_text = seed_text\n",
        "    for _ in range(length):\n",
        "        # Convert seed text to one-hot encoding\n",
        "        input_seq = np.zeros((1, len(seed_text), len(chars)))\n",
        "        for t, char in enumerate(seed_text):\n",
        "            if char in char_to_int:\n",
        "                input_seq[0, t, char_to_int[char]] = 1\n",
        "\n",
        "        # Predict next character\n",
        "        predictions = model.predict(input_seq, verbose=0)[0]\n",
        "\n",
        "        # Apply temperature to predictions\n",
        "        predictions = np.log(predictions) / temperature\n",
        "        exp_preds = np.exp(predictions)\n",
        "        probabilities = exp_preds / np.sum(exp_preds)\n",
        "\n",
        "        # Sample a character based on probabilities\n",
        "        next_index = np.random.choice(len(chars), p=probabilities)\n",
        "        next_char = int_to_char[next_index]\n",
        "\n",
        "        # Append next char and update seed text\n",
        "        generated_text += next_char\n",
        "        seed_text = seed_text[1:] + next_char\n",
        "\n",
        "    return generated_text"
      ],
      "metadata": {
        "id": "pKiPxoOckXf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example seed text from Hamlet\n",
        "seed = \"to be or not to be that is the question\"\n",
        "\n",
        "# Generate text with different temperature settings\n",
        "print(\"\\nLow Temperature (Predictable Output):\")\n",
        "print(generate_text(seed, length=300, temperature=0.2))\n",
        "\n",
        "print(\"\\nHigh Temperature (More Creative Output):\")\n",
        "print(generate_text(seed, length=300, temperature=1.0))"
      ],
      "metadata": {
        "id": "fR8cr_3bkapg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iL1LviDBkdSX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}