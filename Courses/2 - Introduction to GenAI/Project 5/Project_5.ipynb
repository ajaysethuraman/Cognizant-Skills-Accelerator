{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Project: Generating Artistic Abstract Images with GANs\n",
        "## by Ajay Sethuraman\n",
        "\n",
        "**Introduction**\n",
        "\n",
        "In recent years, Generative Adversarial Networks (GANs) have revolutionized the field of artificial intelligence by enabling machines to generate realistic images. This project explores the creative potential of GANs by training a model to generate unique and artistic abstract images. By leveraging deep learning techniques, this project aims to develop a GAN that learns artistic patterns and produces visually compelling results."
      ],
      "metadata": {
        "id": "ptg6onLvFHOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.utils as vutils\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Hyperparameters\n",
        "image_size = 64\n",
        "batch_size = 128\n",
        "latent_dim = 100\n",
        "num_epochs = 100\n",
        "lr = 0.0002\n",
        "beta1 = 0.5\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "O8x__QuLH6TL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset Preparation**\n",
        "\n",
        "To train the GAN effectively, we used the WikiArt dataset, specifically selecting abstract art images. This publicly available dataset provides a diverse collection of artistic styles, allowing the model to learn from a rich variety of abstract compositions. The preprocessing steps included:\n",
        "\n",
        "* Resizing images to a fixed dimension of 64×64 pixels for uniformity.\n",
        "* Normalizing pixel values to the range [-1, 1] to enhance model performance.\n",
        "* Loading the dataset directly using `torchvision.datasets.WikiArt`, eliminating the need for manual data collection and structuring.\n",
        "\n",
        "<br>These steps ensured that the GAN trained on a well-organized and high-quality dataset, improving the fidelity and artistic diversity of the generated images."
      ],
      "metadata": {
        "id": "SD0dLmvGH7ib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations\n",
        "image_size = 64  # Adjust based on model requirements\n",
        "batch_size = 128  # Set an appropriate batch size\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(image_size),\n",
        "    transforms.CenterCrop(image_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Normalize to [-1, 1] range\n",
        "])\n",
        "\n",
        "# Load the WikiArt dataset\n",
        "dataset = datasets.WikiArt(root=\"./data\", category=\"abstract\", transform=transform, download=True)\n",
        "\n",
        "# Create DataLoader\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "Vlwny53uIDHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Architecture**\n",
        "\n",
        "The GAN consists of two neural networks: a Generator and a Discriminator, both utilizing convolutional layers.\n",
        "\n",
        "**Generator**\n",
        "\n",
        "The Generator takes random noise as input and produces abstract images. It uses multiple convolutional transpose layers to progressively refine the output, with batch normalization and ReLU activation functions to improve stability and visual coherence.\n",
        "\n",
        "**Discriminator**\n",
        "\n",
        "The Discriminator’s role is to distinguish real images from the dataset and fake images generated by the Generator. It employs convolutional layers with LeakyReLU activation, batch normalization, and a final sigmoid activation function to classify images.\n",
        "\n",
        "By training both networks simultaneously in an adversarial manner, the Generator improves its ability to create visually convincing abstract images."
      ],
      "metadata": {
        "id": "Cxg681QLIDeL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generator Model\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.ConvTranspose2d(latent_dim, 512, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(128, 3, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "# Discriminator Model\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(3, 128, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(512, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x).view(-1, 1)"
      ],
      "metadata": {
        "id": "IHF1lVnIIJFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training Process**\n",
        "\n",
        "The GAN was trained using an adversarial training loop:\n",
        "\n",
        "* Training the Discriminator: The model learns to differentiate real images from generated ones by optimizing the binary cross-entropy loss.\n",
        "\n",
        "* Training the Generator: The Generator attempts to produce images that can fool the Discriminator, minimizing its loss function.\n",
        "\n",
        "* Monitoring Losses: The training process was carefully balanced to prevent mode collapse and ensure stable learning.\n",
        "\n",
        "The Adam optimizer was used for both models with a learning rate of 0.0002 and beta1 of 0.5 to maintain steady convergence."
      ],
      "metadata": {
        "id": "5FWtptp5IJpz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize models\n",
        "generator = Generator().to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "\n",
        "# Loss and optimizers\n",
        "criterion = nn.BCELoss()\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (real_images, _) in enumerate(dataloader):\n",
        "        real_images = real_images.to(device)\n",
        "        batch_size = real_images.size(0)\n",
        "\n",
        "        # Train Discriminator\n",
        "        optimizer_D.zero_grad()\n",
        "        real_labels = torch.ones(batch_size, 1).to(device)\n",
        "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
        "\n",
        "        outputs = discriminator(real_images)\n",
        "        d_loss_real = criterion(outputs, real_labels)\n",
        "        d_loss_real.backward()\n",
        "\n",
        "        noise = torch.randn(batch_size, latent_dim, 1, 1).to(device)\n",
        "        fake_images = generator(noise)\n",
        "        outputs = discriminator(fake_images.detach())\n",
        "        d_loss_fake = criterion(outputs, fake_labels)\n",
        "        d_loss_fake.backward()\n",
        "\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # Train Generator\n",
        "        optimizer_G.zero_grad()\n",
        "        outputs = discriminator(fake_images)\n",
        "        g_loss = criterion(outputs, real_labels)\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}] Loss D: {d_loss_real + d_loss_fake:.4f}, Loss G: {g_loss:.4f}\")\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        vutils.save_image(fake_images, f\"generated_{epoch}.png\", normalize=True)"
      ],
      "metadata": {
        "id": "ikNWgSOVITQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generating and Evaluating Images**\n",
        "\n",
        "After training, the Generator was used to create new abstract art images by feeding it random noise vectors. The generated images were saved and visually inspected to assess their artistic qualities. Evaluation criteria included:\n",
        "\n",
        "* Visual Diversity: Checking whether the model produces a variety of styles and compositions.\n",
        "\n",
        "* Aesthetic Appeal: Assessing the artistic qualities of the generated images.\n",
        "\n",
        "* Similarity to Real Abstract Art: Ensuring that the outputs resemble real-world abstract art rather than noise or repetitive patterns."
      ],
      "metadata": {
        "id": "A9-6siJ5IWor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Models\n",
        "torch.save(generator.state_dict(), \"generator.pth\")\n",
        "torch.save(discriminator.state_dict(), \"discriminator.pth\")\n",
        "\n",
        "# Generate Sample Images\n",
        "with torch.no_grad():\n",
        "    noise = torch.randn(16, latent_dim, 1, 1).to(device)\n",
        "    generated_images = generator(noise)\n",
        "    vutils.save_image(generated_images, \"final_generated.png\", normalize=True)"
      ],
      "metadata": {
        "id": "ZDknXU3KIcIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reflections and Insights**\n",
        "\n",
        "This project highlights the creative capabilities of GANs in generating artistic images. Throughout the development process, we observed:\n",
        "\n",
        "The importance of proper dataset preprocessing in achieving high-quality outputs.\n",
        "\n",
        "The necessity of balancing Discriminator and Generator training to avoid overfitting or mode collapse.\n",
        "\n",
        "The potential for extending the project by training on specific art styles (e.g., impressionism, cubism) for more stylistic control.\n",
        "\n",
        "**Conclusion**\n",
        "\n",
        "This project successfully demonstrated how GANs can generate artistic abstract images by learning patterns from real-world abstract art datasets. The results illustrate the ability of AI to engage in creative tasks, expanding the applications of deep learning in digital art and design. Future enhancements could include user-controlled parameters for interactive generation, allowing for greater customization of artistic outputs.\n",
        "\n",
        "By blending AI with artistic expression, this project underscores the evolving relationship between technology and creativity, paving the way for new forms of digital art.\n"
      ],
      "metadata": {
        "id": "QBvIzTIpIctk"
      }
    }
  ]
}