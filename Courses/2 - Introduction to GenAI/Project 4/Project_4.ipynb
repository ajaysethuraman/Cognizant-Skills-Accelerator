{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project: AI-Powered Text Completion**\n",
        "## by Ajay Sethuraman\n",
        "\n",
        "**Introduction**\n",
        "\n",
        "This report outlines the development of an AI-powered text completion application using OpenAI's GPT model. The project aims to provide an interactive experience where users input prompts, and the AI generates relevant responses. By implementing this application, we explore the capabilities of generative AI and how different parameters influence text generation. The following sections break down the code, explaining its functionality and design choices.\n",
        "\n",
        "Through this project, we will:\n",
        "\n",
        "* Learn the basics of Generative AI and its working principles.\n",
        "\n",
        "* Develop an application that interacts with a pre-trained AI model.\n",
        "\n",
        "* Experiment with different inputs and evaluate AI-generated responses."
      ],
      "metadata": {
        "id": "SKMYDYve8bW0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRwXtDPy6YcC"
      },
      "outputs": [],
      "source": [
        "!pip install openai python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Importing Required Libraries**\n",
        "\n",
        "The script begins by importing necessary libraries. `openai` is used to interact with the GPT model, and `os` is required to handle environment variables for API key retrieval. Using environment variables ensures security by keeping sensitive credentials out of the source code. We can also save it in a variable if we are using platforms like Google Colab."
      ],
      "metadata": {
        "id": "3sCr09kj8zHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "OPENAI_API_KEY='OPENAI_API_KEY'\n",
        "def get_api_key():\n",
        "    \"\"\"Retrieve API key from environment variable or prompt user.\"\"\"\n",
        "    api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "    if not api_key:\n",
        "        api_key = input(\"Enter your OpenAI API key: \")\n",
        "    return api_key"
      ],
      "metadata": {
        "id": "DDLWMn7p6heh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Retrieving the API Key**\n",
        "\n",
        "This function first checks if an API key is stored in the environment variables. If not found, it prompts the user for manual input. This approach allows flexibility while maintaining security best practices."
      ],
      "metadata": {
        "id": "WedXXefG9I88"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load API key from .env file\n",
        "def load_api_key():\n",
        "    load_dotenv()\n",
        "    return os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "LFgTZNLl8B6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Generating AI Text Completions**\n",
        "\n",
        "This function handles text generation using OpenAI’s API. Key parameters include:\n",
        "\n",
        "* `prompt`: The text input provided by the user.\n",
        "\n",
        "* `model`: Specifies the pre-trained AI model (e.g., text-davinci-003).\n",
        "\n",
        "* `max_tokens`: Defines the length of the AI’s response.\n",
        "\n",
        "* `temperature`: Controls the randomness of the response (lower values make it more deterministic).\n",
        "\n",
        "Error handling is implemented to catch and return API-related issues, ensuring smooth execution."
      ],
      "metadata": {
        "id": "fMpbIoe49YcM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(prompt, model=\"text-davinci-003\", max_tokens=100, temperature=0.7):\n",
        "    \"\"\"Generate text completion using OpenAI API.\"\"\"\n",
        "    openai.api_key = get_api_key()\n",
        "    try:\n",
        "        response = openai.Completion.create(\n",
        "            engine=model,\n",
        "            prompt=prompt,\n",
        "            max_tokens=max_tokens,\n",
        "            temperature=temperature\n",
        "        )\n",
        "        return response[\"choices\"][0][\"text\"].strip()\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\""
      ],
      "metadata": {
        "id": "pWMU9Fhb8QSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Interactive User Input Handling**\n",
        "\n",
        "The main() function creates an interactive session where users input prompts. It includes:\n",
        "\n",
        "* A loop that continuously accepts user input.\n",
        "\n",
        "* A condition to exit when the user types 'exit'.\n",
        "\n",
        "* Input validation to prevent empty prompts.\n",
        "\n",
        "* Calls to generate_text() to fetch AI-generated responses.\n",
        "\n",
        "This structure ensures a user-friendly experience, allowing seamless interaction with the AI."
      ],
      "metadata": {
        "id": "jEH2N6kt9unl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \"\"\"Interactive text completion application.\"\"\"\n",
        "    print(\"\\nAI-Powered Text Completion\\n\")\n",
        "    while True:\n",
        "        prompt = input(\"Enter a prompt (or type 'exit' to quit): \")\n",
        "        if prompt.lower() == 'exit':\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "        if not prompt.strip():\n",
        "            print(\"Please enter a valid prompt.\")\n",
        "            continue\n",
        "        result = generate_text(prompt)\n",
        "        print(\"\\nAI Response:\\n\", result, \"\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "2-BumiO68UJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Running the Application**\n",
        "\n",
        "This standard Python conditional ensures that the script runs only when executed directly, preventing unintended execution when imported as a module.\n",
        "\n",
        "**Observations & Reflections**\n",
        "\n",
        "Through testing, we found that adjusting parameters like `temperature` and `max_tokens` significantly affects the response style. Lower temperatures lead to more structured, predictable outputs, whereas higher values introduce more creativity. Additionally, handling API errors prevents abrupt failures, ensuring a smoother user experience.\n",
        "\n",
        "**Conclusion**\n",
        "\n",
        "This AI-powered text completion project demonstrates how to build an interactive AI application while considering security, usability, and customization. Future improvements could include a graphical interface, additional model options, or extended functionality like summarization and translation. By working with generative AI in this way, we gain deeper insights into its strengths and limitations, enhancing our understanding of modern AI applications."
      ],
      "metadata": {
        "id": "Wm-rJ9T1Bn5k"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BFejRg5OBvSs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}