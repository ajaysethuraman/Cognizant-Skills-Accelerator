# -*- coding: utf-8 -*-
"""C2P1-Final

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hU8lIQBOOEZ5v3BmR2QgMyF8M-JCDSoy

**Project: Decision Trees** <br>by Ajay Sethuraman

This project demonstrates the use of Decision Trees to predict weather conditions using historical data. The implementation follows three key steps: building the model, debugging issues, and evaluating its performance. The dataset contains various weather-related features, and the model is trained to classify different weather conditions.

**Step 1: Importing Required Libraries**

* pandas: Used for data manipulation and analysis.

* seaborn: Imported but not used; could be useful for data visualization.

* sklearn.model_selection.train_test_split: Splits the dataset into training and testing sets.

* sklearn.metrics: Provides performance evaluation metrics.

* sklearn.tree.DecisionTreeClassifier: Implements the Decision Tree algorithm.

* sklearn.preprocessing.LabelEncoder: Encodes categorical labels as numerical values for model training.
"""

import pandas as pd
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.tree import DecisionTreeClassifier
from sklearn.preprocessing import LabelEncoder
data = pd.read_csv('weather_report.csv')

"""The dataset provided contains the following columns:
* date: The date when the weather data was recorded.
* temp_max and temp_min: The temperatures in Celsius at the given time.
* precipitation: The precipitation in millimeters at the given time.
* wind: The wind speed in kilometers per hour at the given location and time.
* weather: The condition of the weather at the given time.<br><br>
This dataset is a perfect candidate for building a decision tree model because it includes key weather variables that can be used to predict various weather conditions. We will focus on predicting weather conditions such as rain or drizzle weather based on the features available.

"""

data.head()

data = data.drop('date',axis=1)

data.info()

"""* The "date" column was removed as it does not contribute to the modelâ€™s decision-making process.

* Missing values were handled appropriately to ensure data integrity.

* The dataset was split into input features (X) and the target variable (y), with categorical values in "weather" encoded using LabelEncoder.

* The data was then split into training (50%) and testing (50%) sets without shuffling.
"""

X,y = data.drop('weather',axis=1), data['weather']

label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)

X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, train_size=0.5, shuffle=False)

model = DecisionTreeClassifier(random_state=8,max_depth=5,min_samples_split=10,min_samples_leaf=5)

model.fit(X_train, y_train)

"""**Model Training**

A DecisionTreeClassifier from the sklearn.tree module was used with the following hyperparameters:

* max_depth=5 to prevent excessive complexity.

* min_samples_split=10 to ensure sufficient samples for splitting nodes.

* min_samples_leaf=5 to avoid overfitting on small subsets of data.

The decision tree model was trained using the fit function on the training data.<br>
<br>To determine whether the model was overfitting or underfitting, the accuracy on both training and testing datasets was examined. A reasonable difference between training and testing accuracy suggested a well-generalized model.

* Tree Depth Adjustment: The depth was controlled using max_depth=5 to prevent overfitting.

* Balanced Data: If the dataset was imbalanced, strategies such as class weighting or resampling could be used.

* Feature Selection: Unnecessary features were removed to enhance model performance and generalization.
"""

y_predicted = model.predict(X_test)

accuracy = (y_predicted == y_test).mean()
print(f'Accuracy: {accuracy}')

"""After training, the model was tested on unseen data, and the following evaluation metrics were used:

* Accuracy: The model achieved an accuracy of 0.8728, indicating strong predictive performance.

* Confusion Matrix: A confusion matrix was generated using ConfusionMatrixDisplay to visualize classification errors and misclassifications. The confusion matrix provides insights into precision and recall.

* Precision and Recall: These metrics were considered for potential class imbalance scenarios.
"""

cm = confusion_matrix(y_test, y_predicted)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_)
disp.plot(cmap="OrRd");

"""This project successfully demonstrated the effectiveness of decision trees for weather prediction. The decision tree was built, trained, and evaluated using a structured approach. Debugging steps ensured that the model was neither overfitting nor underfitting, and the evaluation metrics confirmed its reliability. Further improvements could involve fine-tuning hyperparameters, experimenting with ensemble methods, or using additional meteorological data sources for enhanced accuracy.<br><br>
From the confusion matrix, a few observations stand out:

* Rain and Sun are the dominant outcomes in the dataset. The model predicts these fairly well, likely because they are at opposite extremes.
* "Intermediary" conditions like fog and drizzle were not captured accurately. This suggests that the model could be improved further or that the dataset lacks enough drizzle, fog, or snow examples for better generalization.
"""

