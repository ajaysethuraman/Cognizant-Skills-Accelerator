# -*- coding: utf-8 -*-
"""US 3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_3prs0dmCND8uGRXQOg076DTQAYFIM59
"""

import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.datasets import fashion_mnist
import numpy as np
import matplotlib.pyplot as plt
import tensorflow_datasets as tfds

# Load Fashion MNIST dataset
(x_train, _), (_, _) = fashion_mnist.load_data()
x_train = x_train / 255.0  # Normalize to [0, 1]
x_train = np.expand_dims(x_train, axis=-1)

def build_generator(latent_dim):
    model = models.Sequential([
        layers.Dense(7*7*256, activation='relu', input_dim=latent_dim),
        layers.Reshape((7, 7, 256)),
        layers.Conv2DTranspose(128, kernel_size=3, strides=2, padding='same', activation='relu'),
        layers.Conv2DTranspose(64, kernel_size=3, strides=2, padding='same', activation='relu'),
        layers.Conv2D(1, kernel_size=3, activation='sigmoid', padding='same')
    ])
    return model

def build_discriminator():
    model = models.Sequential([
        layers.Conv2D(64, kernel_size=3, strides=2, padding='same', input_shape=(28, 28, 1)),
        layers.LeakyReLU(0.2),
        layers.Dropout(0.3),
        layers.Conv2D(128, kernel_size=3, strides=2, padding='same'),
        layers.LeakyReLU(0.2),
        layers.Flatten(),
        layers.Dense(1, activation='sigmoid')
    ])
    return model

def build_gan(generator, discriminator):
    discriminator.trainable = False  # We only train the generator in the GAN model
    model = models.Sequential([generator, discriminator])
    return model

latent_dim = 100
discriminator = build_discriminator()
discriminator.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

generator = build_generator(latent_dim)
gan = build_gan(generator, discriminator)
gan.compile(optimizer='adam', loss='binary_crossentropy')

epochs = 1000
batch_size = 64
half_batch = batch_size // 2

for epoch in range(epochs):
    # Train the discriminator
    idx = np.random.randint(0, x_train.shape[0], half_batch)
    real_images = x_train[idx]
    noise = np.random.normal(0, 1, (half_batch, latent_dim))
    generated_images = generator.predict(noise)

    real_labels = np.ones((half_batch, 1))
    fake_labels = np.zeros((half_batch, 1))

    # Train the discriminator on real and fake images
    d_loss_real = discriminator.train_on_batch(real_images, real_labels)
    d_loss_fake = discriminator.train_on_batch(generated_images, fake_labels)
    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)

    # Train the generator via the GAN model
    noise = np.random.normal(0, 1, (batch_size, latent_dim))
    valid_labels = np.ones((batch_size, 1))  # We want the generator to fool the discriminator
    g_loss = gan.train_on_batch(noise, valid_labels)

    # Print the progress every 1000 epochs
    if epoch % 100 == 0:
        print(f"{epoch} [D loss: {d_loss[0]} | D accuracy: {100*d_loss[1]}] [G loss: {g_loss}]")

    # Generate and save images every 500 epochs
    if epoch % 500 == 0:
        noise = np.random.normal(0, 1, (16, latent_dim))
        generated_images = generator.predict(noise)
        generated_images = generated_images * 255.0
        generated_images = generated_images.astype(np.uint8)

        # Plot and display generated images
        fig, axs = plt.subplots(4, 4, figsize=(4, 4))
        cnt = 0
        for i in range(4):
            for j in range(4):
                axs[i, j].imshow(generated_images[cnt, :, :, 0], cmap='gray')
                axs[i, j].axis('off')
                cnt += 1
        plt.show()